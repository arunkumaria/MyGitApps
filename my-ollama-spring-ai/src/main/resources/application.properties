spring.application.name=my-ollama-spring-ai

server.port=8080

# Ollama Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3
spring.ai.ollama.chat.options.temperature=0.7

# Logging
logging.level.org.springframework.ai=INFO
